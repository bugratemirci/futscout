{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default parametrelerle denenen modellerin hyper parametre tuningi ile tekrar sonuçlarının kontrol edilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kütüphanelerin import edilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch İşlemi Uygulanacak Makine Öğrenimi Modellerinin Tanımlanması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Grid Search Uygulanması ve optimum parametrelerin bulunması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "{'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/clustered_data.csv').drop(['id', 'player_name', 'position'], axis=1)\n",
    "X = df.drop(['classes'], axis = 1).values\n",
    "y = df['classes']\n",
    "n_cols = len(np.unique(y))\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "pca = PCA(2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.36, random_state=14)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy',\n",
    "                    return_train_score=False, verbose=1)\n",
    "\n",
    "\n",
    "grid_search=grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "n_neighbors = grid_search.best_params_['n_neighbors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametre tuningi sonucu çıkan optimum başarım : 98.14%\n"
     ]
    }
   ],
   "source": [
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Parametre tuningi sonucu çıkan optimum başarım : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bu parametrenin test seti üzerindeki başarısı : 98.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred=knn.predict(X_test) \n",
    "\n",
    "test_accuracy=accuracy_score(y_test,y_pred)*100\n",
    "test_precision = precision_score(y_test, y_pred, pos_label='positive', average='weighted') * 100\n",
    "test_recall = recall_score(y_test, y_pred, pos_label='positive', average='weighted') * 100\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label='positive', average='weighted') * 100\n",
    "acc_knn = np.array([grid_search.best_params_['n_neighbors'], test_accuracy, test_precision, test_recall, test_f1]).reshape(1,-1)\n",
    "df_acc_knn = pd.DataFrame(acc_knn, columns=['n_neighbors', 'acc', 'precision', 'recall', 'f1'])\n",
    "df_acc_knn.to_csv('knn_acc_recall_f1_precision.csv')\n",
    "print(\"Bu parametrenin test seti üzerindeki başarısı : {:.2f}%\".format(test_accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(\n",
    "    y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(pd.DataFrame(cm),\n",
    "                        annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.savefig('knn_optimum_parameters_cm.png')\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree GridSearch Uygulanması ve optimum parametrelerin bulunması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'criterion': 'gini', 'max_depth': 120}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/clustered_data.csv').drop(['id', 'player_name', 'position'], axis=1)\n",
    "X = df.drop(['classes'], axis = 1).values\n",
    "y = df['classes']\n",
    "n_cols = len(np.unique(y))\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "pca = PCA(2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.36, random_state=14)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [\n",
    "    4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 120, 150]}\n",
    "\n",
    "grid = GridSearchCV(decision_tree, param_grid, cv=10, scoring='accuracy',\n",
    "                    return_train_score=False, verbose=1)\n",
    "\n",
    "\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "criterion = grid_search.best_params_['criterion']\n",
    "max_depth = grid_search.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametre tuningi sonucu çıkan optimum başarım : 97.80%\n"
     ]
    }
   ],
   "source": [
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Parametre tuningi sonucu çıkan optimum başarım : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bu parametrenin test seti üzerindeki başarısı : 97.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred=decision_tree.predict(X_test) \n",
    "\n",
    "test_accuracy=accuracy_score(y_test,y_pred)*100\n",
    "test_precision = precision_score(y_test, y_pred, pos_label='positive', average='weighted') * 100\n",
    "test_recall = recall_score(y_test, y_pred, pos_label='positive', average='weighted') * 100\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label='positive', average='weighted') * 100\n",
    "acc_dt = np.array([grid_search.best_params_['criterion'], grid_search.best_params_['max_depth'], test_accuracy, test_precision, test_recall, test_f1]).reshape(1,-1)\n",
    "df_acc_dt = pd.DataFrame(acc_dt, columns=['criterion','max_depth','acc', 'precision', 'recall', 'f1'])\n",
    "df_acc_dt.to_csv('dt_acc_recall_f1_precision.csv')\n",
    "print(\"Bu parametrenin test seti üzerindeki başarısı : {:.2f}%\".format(test_accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(\n",
    "    y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(pd.DataFrame(cm),\n",
    "                        annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.savefig('decision_tree_optimum_parameters_cm.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ann ile çeşitli batch-size değerlerinin denenmesi\n",
    "[8, 16, 32, 64, 128, 256] değerleriyle denemeler yapılmış ve test seti üzerindeki başarıları kıyaslanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import callbacks\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "def createModel(n_cols):\n",
    "\n",
    "    model = keras.Sequential([\n",
    "\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=64, activation='relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "        keras.layers.Dense(units=32, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(units=8, activation='relu'),\n",
    "        keras.layers.Dense(units=n_cols, activation='softmax'),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    optim = Adam(lr=0.001)\n",
    "    model.compile(optimizer=optim, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_model(X_train, y_train, X_test, y_test, batch_size):\n",
    "        early_stopping = callbacks.EarlyStopping(\n",
    "        min_delta=0.00001,\n",
    "        patience=6,\n",
    "        restore_best_weights=True)\n",
    "        model = createModel(n_cols=n_cols)\n",
    "\n",
    "        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=1000, callbacks=[\n",
    "                        early_stopping], validation_split=0.2, verbose = 2)\n",
    "        model.save('model/model_sc_pca_batch_size_'+str(batch_size)+'.h5')\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.subplot(211)\n",
    "        plt.title('Loss')\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='test')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(212)\n",
    "        plt.title('Accuracy')\n",
    "        plt.plot(history.history['accuracy'], label='train')\n",
    "        plt.plot(history.history['val_accuracy'], label='test')\n",
    "        plt.legend()\n",
    "        plt.savefig('ann_default_parameters_acc_loss_batch_size_'+str(batch_size)+'.png')\n",
    "        plt.clf()\n",
    "        y_pred = model.predict(X_test)\n",
    "        cnf_matrix = metrics.confusion_matrix(\n",
    "                y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        sns.heatmap(pd.DataFrame(cnf_matrix),\n",
    "                        annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "        plt.title('Confusion matrix', y=1.1)\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        plt.savefig('ann_default_parameters_cm_batch_size_'+str(batch_size)+'.png')\n",
    "        plt.clf()\n",
    "        FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "        FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "        TP = np.diag(cnf_matrix)\n",
    "        TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "        acc = (TP + TN) / (TP + FP + FN + TN)\n",
    "        sen = TP / (TP + FN)\n",
    "        pre = TP / (TP + FP)\n",
    "        spe = TN / (TN + FP)\n",
    "        f1 = (2 * (pre * sen)) / (pre + sen)\n",
    "\n",
    "        acc_scores_ann.append([batch_size, np.mean(acc), np.mean(sen), np.mean(pre), np.mean(spe),np.mean(f1)])\n",
    "\n",
    "        print(\"batch_size {} -> Bu parametrenin test seti üzerindeki başarısı : {:.2f}%\".format(batch_size, test_accuracy))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores_ann = []\n",
    "df = pd.read_csv('data/clustered_data.csv').drop(['id', 'player_name', 'position'], axis=1)\n",
    "X = df.drop(['classes'], axis = 1).values\n",
    "y = df['classes']\n",
    "n_cols = len(np.unique(y))\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "pca = PCA(2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.36, random_state=14)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473/473 - 5s - loss: 1.2772 - accuracy: 0.4956 - val_loss: 0.8716 - val_accuracy: 0.6571 - 5s/epoch - 11ms/step\n",
      "Epoch 2/1000\n",
      "473/473 - 4s - loss: 0.8175 - accuracy: 0.7056 - val_loss: 0.5311 - val_accuracy: 0.8646 - 4s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "473/473 - 4s - loss: 0.5591 - accuracy: 0.8128 - val_loss: 0.3854 - val_accuracy: 0.8624 - 4s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "473/473 - 4s - loss: 0.4536 - accuracy: 0.8472 - val_loss: 0.2600 - val_accuracy: 0.9228 - 4s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "473/473 - 3s - loss: 0.3932 - accuracy: 0.8605 - val_loss: 0.3250 - val_accuracy: 0.8899 - 3s/epoch - 7ms/step\n",
      "Epoch 6/1000\n",
      "473/473 - 3s - loss: 0.3636 - accuracy: 0.8782 - val_loss: 0.2211 - val_accuracy: 0.9090 - 3s/epoch - 7ms/step\n",
      "Epoch 7/1000\n",
      "473/473 - 3s - loss: 0.3423 - accuracy: 0.8896 - val_loss: 0.1802 - val_accuracy: 0.9460 - 3s/epoch - 6ms/step\n",
      "Epoch 8/1000\n",
      "473/473 - 2s - loss: 0.2908 - accuracy: 0.9110 - val_loss: 0.1692 - val_accuracy: 0.9312 - 2s/epoch - 5ms/step\n",
      "Epoch 9/1000\n",
      "473/473 - 3s - loss: 0.2854 - accuracy: 0.9129 - val_loss: 0.1394 - val_accuracy: 0.9534 - 3s/epoch - 7ms/step\n",
      "Epoch 10/1000\n",
      "473/473 - 4s - loss: 0.2623 - accuracy: 0.9166 - val_loss: 0.1595 - val_accuracy: 0.9312 - 4s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "473/473 - 2s - loss: 0.2443 - accuracy: 0.9158 - val_loss: 0.1545 - val_accuracy: 0.9429 - 2s/epoch - 5ms/step\n",
      "Epoch 12/1000\n",
      "473/473 - 3s - loss: 0.2505 - accuracy: 0.9198 - val_loss: 0.1672 - val_accuracy: 0.9397 - 3s/epoch - 6ms/step\n",
      "Epoch 13/1000\n",
      "473/473 - 3s - loss: 0.2525 - accuracy: 0.9174 - val_loss: 0.1162 - val_accuracy: 0.9481 - 3s/epoch - 6ms/step\n",
      "Epoch 14/1000\n",
      "473/473 - 3s - loss: 0.2332 - accuracy: 0.9235 - val_loss: 0.1766 - val_accuracy: 0.9376 - 3s/epoch - 5ms/step\n",
      "Epoch 15/1000\n",
      "473/473 - 3s - loss: 0.2341 - accuracy: 0.9232 - val_loss: 0.1237 - val_accuracy: 0.9460 - 3s/epoch - 6ms/step\n",
      "Epoch 16/1000\n",
      "473/473 - 3s - loss: 0.2311 - accuracy: 0.9187 - val_loss: 0.1089 - val_accuracy: 0.9630 - 3s/epoch - 7ms/step\n",
      "Epoch 17/1000\n",
      "473/473 - 4s - loss: 0.2197 - accuracy: 0.9259 - val_loss: 0.1179 - val_accuracy: 0.9545 - 4s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "473/473 - 3s - loss: 0.2126 - accuracy: 0.9293 - val_loss: 0.1025 - val_accuracy: 0.9619 - 3s/epoch - 7ms/step\n",
      "Epoch 19/1000\n",
      "473/473 - 3s - loss: 0.1902 - accuracy: 0.9359 - val_loss: 0.2472 - val_accuracy: 0.9333 - 3s/epoch - 7ms/step\n",
      "Epoch 20/1000\n",
      "473/473 - 3s - loss: 0.2106 - accuracy: 0.9349 - val_loss: 0.1792 - val_accuracy: 0.9376 - 3s/epoch - 7ms/step\n",
      "Epoch 21/1000\n",
      "473/473 - 3s - loss: 0.1933 - accuracy: 0.9370 - val_loss: 0.1197 - val_accuracy: 0.9534 - 3s/epoch - 7ms/step\n",
      "Epoch 22/1000\n",
      "473/473 - 2s - loss: 0.1916 - accuracy: 0.9367 - val_loss: 0.1571 - val_accuracy: 0.9439 - 2s/epoch - 5ms/step\n",
      "Epoch 23/1000\n",
      "473/473 - 3s - loss: 0.2056 - accuracy: 0.9309 - val_loss: 0.1480 - val_accuracy: 0.9524 - 3s/epoch - 6ms/step\n",
      "Epoch 24/1000\n",
      "473/473 - 2s - loss: 0.2046 - accuracy: 0.9320 - val_loss: 0.1020 - val_accuracy: 0.9608 - 2s/epoch - 5ms/step\n",
      "Epoch 25/1000\n",
      "473/473 - 3s - loss: 0.1677 - accuracy: 0.9433 - val_loss: 0.1213 - val_accuracy: 0.9556 - 3s/epoch - 7ms/step\n",
      "Epoch 26/1000\n",
      "473/473 - 4s - loss: 0.1963 - accuracy: 0.9380 - val_loss: 0.0761 - val_accuracy: 0.9735 - 4s/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "473/473 - 3s - loss: 0.1679 - accuracy: 0.9415 - val_loss: 0.1284 - val_accuracy: 0.9534 - 3s/epoch - 7ms/step\n",
      "Epoch 28/1000\n",
      "473/473 - 2s - loss: 0.1723 - accuracy: 0.9365 - val_loss: 0.1002 - val_accuracy: 0.9693 - 2s/epoch - 5ms/step\n",
      "Epoch 29/1000\n",
      "473/473 - 3s - loss: 0.1678 - accuracy: 0.9436 - val_loss: 0.0815 - val_accuracy: 0.9683 - 3s/epoch - 7ms/step\n",
      "Epoch 30/1000\n",
      "473/473 - 3s - loss: 0.1719 - accuracy: 0.9407 - val_loss: 0.1133 - val_accuracy: 0.9619 - 3s/epoch - 7ms/step\n",
      "Epoch 31/1000\n",
      "473/473 - 3s - loss: 0.1674 - accuracy: 0.9423 - val_loss: 0.1022 - val_accuracy: 0.9661 - 3s/epoch - 6ms/step\n",
      "Epoch 32/1000\n",
      "473/473 - 4s - loss: 0.1611 - accuracy: 0.9484 - val_loss: 0.1180 - val_accuracy: 0.9619 - 4s/epoch - 8ms/step\n",
      "batch_size 8 -> Bu parametrenin test seti üzerindeki başarısı : 97.89%\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 - 3s - loss: 1.4547 - accuracy: 0.4355 - val_loss: 1.0479 - val_accuracy: 0.5884 - 3s/epoch - 11ms/step\n",
      "Epoch 2/1000\n",
      "237/237 - 2s - loss: 0.9476 - accuracy: 0.6664 - val_loss: 0.5932 - val_accuracy: 0.7947 - 2s/epoch - 7ms/step\n",
      "Epoch 3/1000\n",
      "237/237 - 2s - loss: 0.6366 - accuracy: 0.7628 - val_loss: 0.3986 - val_accuracy: 0.8741 - 2s/epoch - 7ms/step\n",
      "Epoch 4/1000\n",
      "237/237 - 2s - loss: 0.5322 - accuracy: 0.8242 - val_loss: 0.2914 - val_accuracy: 0.9376 - 2s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "237/237 - 2s - loss: 0.4403 - accuracy: 0.8501 - val_loss: 0.2487 - val_accuracy: 0.9450 - 2s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "237/237 - 2s - loss: 0.3806 - accuracy: 0.8666 - val_loss: 0.2417 - val_accuracy: 0.9397 - 2s/epoch - 7ms/step\n",
      "Epoch 7/1000\n",
      "237/237 - 2s - loss: 0.3587 - accuracy: 0.8848 - val_loss: 0.2213 - val_accuracy: 0.9397 - 2s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "237/237 - 1s - loss: 0.3446 - accuracy: 0.8809 - val_loss: 0.1829 - val_accuracy: 0.9450 - 1s/epoch - 5ms/step\n",
      "Epoch 9/1000\n",
      "237/237 - 1s - loss: 0.3086 - accuracy: 0.8959 - val_loss: 0.1805 - val_accuracy: 0.9460 - 1s/epoch - 5ms/step\n",
      "Epoch 10/1000\n",
      "237/237 - 1s - loss: 0.3141 - accuracy: 0.8891 - val_loss: 0.1253 - val_accuracy: 0.9714 - 1s/epoch - 5ms/step\n",
      "Epoch 11/1000\n",
      "237/237 - 2s - loss: 0.2768 - accuracy: 0.9050 - val_loss: 0.1240 - val_accuracy: 0.9587 - 2s/epoch - 7ms/step\n",
      "Epoch 12/1000\n",
      "237/237 - 2s - loss: 0.2664 - accuracy: 0.9073 - val_loss: 0.1601 - val_accuracy: 0.9598 - 2s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "237/237 - 2s - loss: 0.2779 - accuracy: 0.9023 - val_loss: 0.1160 - val_accuracy: 0.9640 - 2s/epoch - 7ms/step\n",
      "Epoch 14/1000\n",
      "237/237 - 2s - loss: 0.2722 - accuracy: 0.9124 - val_loss: 0.1114 - val_accuracy: 0.9566 - 2s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "237/237 - 2s - loss: 0.2651 - accuracy: 0.9087 - val_loss: 0.1265 - val_accuracy: 0.9630 - 2s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "237/237 - 2s - loss: 0.2454 - accuracy: 0.9166 - val_loss: 0.1600 - val_accuracy: 0.9513 - 2s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "237/237 - 2s - loss: 0.2426 - accuracy: 0.9142 - val_loss: 0.1078 - val_accuracy: 0.9640 - 2s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "237/237 - 2s - loss: 0.2362 - accuracy: 0.9192 - val_loss: 0.1230 - val_accuracy: 0.9471 - 2s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "237/237 - 2s - loss: 0.2351 - accuracy: 0.9230 - val_loss: 0.1007 - val_accuracy: 0.9651 - 2s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "237/237 - 2s - loss: 0.2142 - accuracy: 0.9264 - val_loss: 0.0933 - val_accuracy: 0.9704 - 2s/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "237/237 - 2s - loss: 0.2186 - accuracy: 0.9245 - val_loss: 0.1136 - val_accuracy: 0.9524 - 2s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "237/237 - 2s - loss: 0.2260 - accuracy: 0.9190 - val_loss: 0.1098 - val_accuracy: 0.9651 - 2s/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "237/237 - 2s - loss: 0.2071 - accuracy: 0.9290 - val_loss: 0.0883 - val_accuracy: 0.9735 - 2s/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "237/237 - 2s - loss: 0.1864 - accuracy: 0.9388 - val_loss: 0.2092 - val_accuracy: 0.9312 - 2s/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "237/237 - 2s - loss: 0.2347 - accuracy: 0.9232 - val_loss: 0.2292 - val_accuracy: 0.9217 - 2s/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "237/237 - 2s - loss: 0.2259 - accuracy: 0.9166 - val_loss: 0.1380 - val_accuracy: 0.9471 - 2s/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "237/237 - 2s - loss: 0.1937 - accuracy: 0.9328 - val_loss: 0.1026 - val_accuracy: 0.9672 - 2s/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "237/237 - 2s - loss: 0.1970 - accuracy: 0.9253 - val_loss: 0.0848 - val_accuracy: 0.9714 - 2s/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "237/237 - 2s - loss: 0.2275 - accuracy: 0.9230 - val_loss: 0.0792 - val_accuracy: 0.9714 - 2s/epoch - 8ms/step\n",
      "Epoch 30/1000\n",
      "237/237 - 2s - loss: 0.1975 - accuracy: 0.9288 - val_loss: 0.1216 - val_accuracy: 0.9661 - 2s/epoch - 8ms/step\n",
      "Epoch 31/1000\n",
      "237/237 - 2s - loss: 0.1896 - accuracy: 0.9296 - val_loss: 0.0847 - val_accuracy: 0.9683 - 2s/epoch - 8ms/step\n",
      "Epoch 32/1000\n",
      "237/237 - 2s - loss: 0.1951 - accuracy: 0.9362 - val_loss: 0.0976 - val_accuracy: 0.9587 - 2s/epoch - 8ms/step\n",
      "Epoch 33/1000\n",
      "237/237 - 2s - loss: 0.1762 - accuracy: 0.9362 - val_loss: 0.0923 - val_accuracy: 0.9587 - 2s/epoch - 8ms/step\n",
      "Epoch 34/1000\n",
      "237/237 - 2s - loss: 0.1738 - accuracy: 0.9359 - val_loss: 0.1304 - val_accuracy: 0.9481 - 2s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "237/237 - 2s - loss: 0.1787 - accuracy: 0.9412 - val_loss: 0.1338 - val_accuracy: 0.9503 - 2s/epoch - 8ms/step\n",
      "batch_size 16 -> Bu parametrenin test seti üzerindeki başarısı : 97.89%\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 - 2s - loss: 1.6079 - accuracy: 0.4181 - val_loss: 1.1298 - val_accuracy: 0.5259 - 2s/epoch - 14ms/step\n",
      "Epoch 2/1000\n",
      "119/119 - 1s - loss: 1.0775 - accuracy: 0.5510 - val_loss: 0.8017 - val_accuracy: 0.7037 - 1s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "119/119 - 1s - loss: 0.8297 - accuracy: 0.6894 - val_loss: 0.6039 - val_accuracy: 0.8381 - 1s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "119/119 - 1s - loss: 0.6512 - accuracy: 0.7861 - val_loss: 0.4210 - val_accuracy: 0.8836 - 1s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "119/119 - 1s - loss: 0.6009 - accuracy: 0.8041 - val_loss: 0.3250 - val_accuracy: 0.9079 - 928ms/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "119/119 - 1s - loss: 0.4680 - accuracy: 0.8520 - val_loss: 0.2789 - val_accuracy: 0.9090 - 862ms/epoch - 7ms/step\n",
      "Epoch 7/1000\n",
      "119/119 - 1s - loss: 0.4457 - accuracy: 0.8491 - val_loss: 0.2490 - val_accuracy: 0.9407 - 926ms/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "119/119 - 1s - loss: 0.3959 - accuracy: 0.8721 - val_loss: 0.2320 - val_accuracy: 0.9460 - 980ms/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "119/119 - 1s - loss: 0.3567 - accuracy: 0.8920 - val_loss: 0.1899 - val_accuracy: 0.9608 - 979ms/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "119/119 - 1s - loss: 0.3134 - accuracy: 0.9039 - val_loss: 0.1861 - val_accuracy: 0.9354 - 1s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "119/119 - 1s - loss: 0.3359 - accuracy: 0.8959 - val_loss: 0.1771 - val_accuracy: 0.9471 - 1s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "119/119 - 1s - loss: 0.3798 - accuracy: 0.8862 - val_loss: 0.2092 - val_accuracy: 0.9333 - 1s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "119/119 - 1s - loss: 0.2849 - accuracy: 0.9137 - val_loss: 0.1826 - val_accuracy: 0.9429 - 876ms/epoch - 7ms/step\n",
      "Epoch 14/1000\n",
      "119/119 - 1s - loss: 0.2715 - accuracy: 0.9150 - val_loss: 0.1440 - val_accuracy: 0.9524 - 953ms/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "119/119 - 1s - loss: 0.2721 - accuracy: 0.9092 - val_loss: 0.1389 - val_accuracy: 0.9492 - 862ms/epoch - 7ms/step\n",
      "Epoch 16/1000\n",
      "119/119 - 1s - loss: 0.2580 - accuracy: 0.9132 - val_loss: 0.1978 - val_accuracy: 0.9238 - 866ms/epoch - 7ms/step\n",
      "Epoch 17/1000\n",
      "119/119 - 1s - loss: 0.2475 - accuracy: 0.9214 - val_loss: 0.1368 - val_accuracy: 0.9566 - 1s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "119/119 - 1s - loss: 0.2259 - accuracy: 0.9253 - val_loss: 0.1368 - val_accuracy: 0.9608 - 999ms/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "119/119 - 1s - loss: 0.2233 - accuracy: 0.9267 - val_loss: 0.1106 - val_accuracy: 0.9587 - 977ms/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "119/119 - 1s - loss: 0.2172 - accuracy: 0.9277 - val_loss: 0.1266 - val_accuracy: 0.9524 - 841ms/epoch - 7ms/step\n",
      "Epoch 21/1000\n",
      "119/119 - 1s - loss: 0.2221 - accuracy: 0.9248 - val_loss: 0.1904 - val_accuracy: 0.9418 - 855ms/epoch - 7ms/step\n",
      "Epoch 22/1000\n",
      "119/119 - 1s - loss: 0.2230 - accuracy: 0.9267 - val_loss: 0.1339 - val_accuracy: 0.9481 - 985ms/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "119/119 - 1s - loss: 0.2229 - accuracy: 0.9245 - val_loss: 0.1423 - val_accuracy: 0.9503 - 1s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "119/119 - 1s - loss: 0.2115 - accuracy: 0.9272 - val_loss: 0.1174 - val_accuracy: 0.9460 - 966ms/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "119/119 - 1s - loss: 0.2012 - accuracy: 0.9322 - val_loss: 0.1495 - val_accuracy: 0.9418 - 999ms/epoch - 8ms/step\n",
      "batch_size 32 -> Bu parametrenin test seti üzerindeki başarısı : 97.89%\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bugra\\AppData\\Local\\Temp\\ipykernel_2232\\901433257.py:44: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pre = TP / (TP + FP)\n",
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 1s - loss: 1.7316 - accuracy: 0.3471 - val_loss: 1.2123 - val_accuracy: 0.5693 - 1s/epoch - 19ms/step\n",
      "Epoch 2/1000\n",
      "60/60 - 1s - loss: 1.1934 - accuracy: 0.5412 - val_loss: 0.9175 - val_accuracy: 0.7175 - 522ms/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "60/60 - 1s - loss: 0.9772 - accuracy: 0.6373 - val_loss: 0.7746 - val_accuracy: 0.7344 - 515ms/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "60/60 - 1s - loss: 0.8706 - accuracy: 0.6942 - val_loss: 0.6892 - val_accuracy: 0.8074 - 517ms/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "60/60 - 1s - loss: 0.7605 - accuracy: 0.7337 - val_loss: 0.5629 - val_accuracy: 0.8466 - 508ms/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "60/60 - 1s - loss: 0.6577 - accuracy: 0.7813 - val_loss: 0.4573 - val_accuracy: 0.8677 - 515ms/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "60/60 - 1s - loss: 0.5642 - accuracy: 0.8107 - val_loss: 0.3978 - val_accuracy: 0.8878 - 504ms/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "60/60 - 1s - loss: 0.5296 - accuracy: 0.8091 - val_loss: 0.3468 - val_accuracy: 0.8931 - 512ms/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "60/60 - 1s - loss: 0.5031 - accuracy: 0.8247 - val_loss: 0.3217 - val_accuracy: 0.8984 - 510ms/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "60/60 - 1s - loss: 0.4614 - accuracy: 0.8351 - val_loss: 0.2952 - val_accuracy: 0.9048 - 532ms/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "60/60 - 0s - loss: 0.4524 - accuracy: 0.8398 - val_loss: 0.3163 - val_accuracy: 0.8995 - 439ms/epoch - 7ms/step\n",
      "Epoch 12/1000\n",
      "60/60 - 0s - loss: 0.4342 - accuracy: 0.8446 - val_loss: 0.2785 - val_accuracy: 0.9079 - 442ms/epoch - 7ms/step\n",
      "Epoch 13/1000\n",
      "60/60 - 0s - loss: 0.4053 - accuracy: 0.8451 - val_loss: 0.2600 - val_accuracy: 0.9048 - 438ms/epoch - 7ms/step\n",
      "Epoch 14/1000\n",
      "60/60 - 0s - loss: 0.3671 - accuracy: 0.8594 - val_loss: 0.2637 - val_accuracy: 0.9079 - 460ms/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "60/60 - 1s - loss: 0.3655 - accuracy: 0.8634 - val_loss: 0.2399 - val_accuracy: 0.9101 - 509ms/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "60/60 - 1s - loss: 0.3494 - accuracy: 0.8676 - val_loss: 0.2308 - val_accuracy: 0.9037 - 522ms/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "60/60 - 1s - loss: 0.3504 - accuracy: 0.8573 - val_loss: 0.2308 - val_accuracy: 0.9037 - 504ms/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "60/60 - 0s - loss: 0.3511 - accuracy: 0.8668 - val_loss: 0.1972 - val_accuracy: 0.9153 - 490ms/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "60/60 - 1s - loss: 0.3297 - accuracy: 0.8713 - val_loss: 0.2301 - val_accuracy: 0.9111 - 504ms/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "60/60 - 0s - loss: 0.3124 - accuracy: 0.8838 - val_loss: 0.2096 - val_accuracy: 0.9344 - 487ms/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "60/60 - 1s - loss: 0.3153 - accuracy: 0.8814 - val_loss: 0.1930 - val_accuracy: 0.9386 - 510ms/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "60/60 - 1s - loss: 0.3039 - accuracy: 0.8907 - val_loss: 0.1712 - val_accuracy: 0.9354 - 510ms/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "60/60 - 1s - loss: 0.3060 - accuracy: 0.8864 - val_loss: 0.1604 - val_accuracy: 0.9407 - 526ms/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "60/60 - 0s - loss: 0.2859 - accuracy: 0.8962 - val_loss: 0.1448 - val_accuracy: 0.9651 - 498ms/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "60/60 - 1s - loss: 0.2976 - accuracy: 0.8907 - val_loss: 0.1568 - val_accuracy: 0.9365 - 523ms/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "60/60 - 0s - loss: 0.2816 - accuracy: 0.8952 - val_loss: 0.1949 - val_accuracy: 0.9418 - 490ms/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "60/60 - 1s - loss: 0.6281 - accuracy: 0.8173 - val_loss: 0.1971 - val_accuracy: 0.9238 - 502ms/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "60/60 - 1s - loss: 0.3279 - accuracy: 0.8732 - val_loss: 0.1548 - val_accuracy: 0.9481 - 519ms/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "60/60 - 1s - loss: 0.2767 - accuracy: 0.9020 - val_loss: 0.1405 - val_accuracy: 0.9503 - 524ms/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "60/60 - 0s - loss: 0.2695 - accuracy: 0.8965 - val_loss: 0.1278 - val_accuracy: 0.9513 - 494ms/epoch - 8ms/step\n",
      "Epoch 31/1000\n",
      "60/60 - 0s - loss: 0.2623 - accuracy: 0.9039 - val_loss: 0.1240 - val_accuracy: 0.9566 - 486ms/epoch - 8ms/step\n",
      "Epoch 32/1000\n",
      "60/60 - 1s - loss: 0.2772 - accuracy: 0.8989 - val_loss: 0.1263 - val_accuracy: 0.9545 - 566ms/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "60/60 - 1s - loss: 0.2516 - accuracy: 0.9142 - val_loss: 0.1212 - val_accuracy: 0.9492 - 517ms/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "60/60 - 0s - loss: 0.2466 - accuracy: 0.9097 - val_loss: 0.1204 - val_accuracy: 0.9556 - 425ms/epoch - 7ms/step\n",
      "Epoch 35/1000\n",
      "60/60 - 0s - loss: 0.2349 - accuracy: 0.9182 - val_loss: 0.1227 - val_accuracy: 0.9556 - 446ms/epoch - 7ms/step\n",
      "Epoch 36/1000\n",
      "60/60 - 0s - loss: 0.3071 - accuracy: 0.8817 - val_loss: 0.1987 - val_accuracy: 0.9175 - 426ms/epoch - 7ms/step\n",
      "Epoch 37/1000\n",
      "60/60 - 0s - loss: 0.2784 - accuracy: 0.8991 - val_loss: 0.1482 - val_accuracy: 0.9651 - 498ms/epoch - 8ms/step\n",
      "Epoch 38/1000\n",
      "60/60 - 0s - loss: 0.2543 - accuracy: 0.9118 - val_loss: 0.1644 - val_accuracy: 0.9503 - 445ms/epoch - 7ms/step\n",
      "Epoch 39/1000\n",
      "60/60 - 0s - loss: 0.2375 - accuracy: 0.9142 - val_loss: 0.1241 - val_accuracy: 0.9534 - 421ms/epoch - 7ms/step\n",
      "Epoch 40/1000\n",
      "60/60 - 0s - loss: 0.2336 - accuracy: 0.9179 - val_loss: 0.1275 - val_accuracy: 0.9556 - 410ms/epoch - 7ms/step\n",
      "batch_size 64 -> Bu parametrenin test seti üzerindeki başarısı : 97.89%\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 1s - loss: 1.9167 - accuracy: 0.2886 - val_loss: 1.5116 - val_accuracy: 0.3143 - 877ms/epoch - 29ms/step\n",
      "Epoch 2/1000\n",
      "30/30 - 0s - loss: 1.5009 - accuracy: 0.4014 - val_loss: 1.2306 - val_accuracy: 0.5651 - 317ms/epoch - 11ms/step\n",
      "Epoch 3/1000\n",
      "30/30 - 0s - loss: 1.2648 - accuracy: 0.5004 - val_loss: 1.0016 - val_accuracy: 0.6212 - 299ms/epoch - 10ms/step\n",
      "Epoch 4/1000\n",
      "30/30 - 0s - loss: 1.0890 - accuracy: 0.5690 - val_loss: 0.8634 - val_accuracy: 0.7122 - 287ms/epoch - 10ms/step\n",
      "Epoch 5/1000\n",
      "30/30 - 0s - loss: 0.9499 - accuracy: 0.6219 - val_loss: 0.7259 - val_accuracy: 0.7481 - 285ms/epoch - 10ms/step\n",
      "Epoch 6/1000\n",
      "30/30 - 0s - loss: 0.8209 - accuracy: 0.6910 - val_loss: 0.5921 - val_accuracy: 0.8222 - 310ms/epoch - 10ms/step\n",
      "Epoch 7/1000\n",
      "30/30 - 0s - loss: 0.7115 - accuracy: 0.7408 - val_loss: 0.4565 - val_accuracy: 0.8720 - 287ms/epoch - 10ms/step\n",
      "Epoch 8/1000\n",
      "30/30 - 0s - loss: 0.6202 - accuracy: 0.7866 - val_loss: 0.3742 - val_accuracy: 0.9016 - 294ms/epoch - 10ms/step\n",
      "Epoch 9/1000\n",
      "30/30 - 0s - loss: 0.5426 - accuracy: 0.8067 - val_loss: 0.3079 - val_accuracy: 0.9196 - 293ms/epoch - 10ms/step\n",
      "Epoch 10/1000\n",
      "30/30 - 0s - loss: 0.4952 - accuracy: 0.8223 - val_loss: 0.2665 - val_accuracy: 0.9132 - 304ms/epoch - 10ms/step\n",
      "Epoch 11/1000\n",
      "30/30 - 0s - loss: 0.4634 - accuracy: 0.8358 - val_loss: 0.2645 - val_accuracy: 0.9270 - 283ms/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "30/30 - 0s - loss: 0.4358 - accuracy: 0.8446 - val_loss: 0.2148 - val_accuracy: 0.9386 - 287ms/epoch - 10ms/step\n",
      "Epoch 13/1000\n",
      "30/30 - 0s - loss: 0.4067 - accuracy: 0.8589 - val_loss: 0.2237 - val_accuracy: 0.9196 - 283ms/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "30/30 - 0s - loss: 0.3985 - accuracy: 0.8552 - val_loss: 0.1972 - val_accuracy: 0.9407 - 289ms/epoch - 10ms/step\n",
      "Epoch 15/1000\n",
      "30/30 - 0s - loss: 0.3594 - accuracy: 0.8695 - val_loss: 0.1884 - val_accuracy: 0.9238 - 279ms/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "30/30 - 0s - loss: 0.3758 - accuracy: 0.8639 - val_loss: 0.2009 - val_accuracy: 0.9196 - 277ms/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "30/30 - 0s - loss: 0.3359 - accuracy: 0.8827 - val_loss: 0.1638 - val_accuracy: 0.9524 - 275ms/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "30/30 - 0s - loss: 0.3336 - accuracy: 0.8761 - val_loss: 0.1671 - val_accuracy: 0.9429 - 277ms/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "30/30 - 0s - loss: 0.3177 - accuracy: 0.8793 - val_loss: 0.1599 - val_accuracy: 0.9492 - 289ms/epoch - 10ms/step\n",
      "Epoch 20/1000\n",
      "30/30 - 0s - loss: 0.3226 - accuracy: 0.8848 - val_loss: 0.1557 - val_accuracy: 0.9524 - 280ms/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "30/30 - 0s - loss: 0.2964 - accuracy: 0.8946 - val_loss: 0.1351 - val_accuracy: 0.9566 - 291ms/epoch - 10ms/step\n",
      "Epoch 22/1000\n",
      "30/30 - 0s - loss: 0.2938 - accuracy: 0.8981 - val_loss: 0.1370 - val_accuracy: 0.9577 - 236ms/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "30/30 - 0s - loss: 0.2923 - accuracy: 0.8954 - val_loss: 0.1364 - val_accuracy: 0.9577 - 236ms/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "30/30 - 0s - loss: 0.2976 - accuracy: 0.8933 - val_loss: 0.1426 - val_accuracy: 0.9587 - 238ms/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "30/30 - 0s - loss: 0.2767 - accuracy: 0.9012 - val_loss: 0.1312 - val_accuracy: 0.9545 - 238ms/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "30/30 - 0s - loss: 0.2511 - accuracy: 0.9050 - val_loss: 0.1200 - val_accuracy: 0.9651 - 239ms/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "30/30 - 0s - loss: 0.2654 - accuracy: 0.9036 - val_loss: 0.1436 - val_accuracy: 0.9397 - 238ms/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "30/30 - 0s - loss: 0.2607 - accuracy: 0.9034 - val_loss: 0.1340 - val_accuracy: 0.9503 - 240ms/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "30/30 - 0s - loss: 0.2568 - accuracy: 0.9071 - val_loss: 0.1252 - val_accuracy: 0.9556 - 262ms/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "30/30 - 0s - loss: 0.2607 - accuracy: 0.9034 - val_loss: 0.1030 - val_accuracy: 0.9640 - 283ms/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "30/30 - 0s - loss: 0.2380 - accuracy: 0.9145 - val_loss: 0.1065 - val_accuracy: 0.9651 - 269ms/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "30/30 - 0s - loss: 0.2379 - accuracy: 0.9161 - val_loss: 0.1389 - val_accuracy: 0.9524 - 269ms/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "30/30 - 0s - loss: 0.2399 - accuracy: 0.9121 - val_loss: 0.0977 - val_accuracy: 0.9661 - 272ms/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "30/30 - 0s - loss: 0.2326 - accuracy: 0.9166 - val_loss: 0.1099 - val_accuracy: 0.9630 - 270ms/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "30/30 - 0s - loss: 0.2234 - accuracy: 0.9185 - val_loss: 0.0949 - val_accuracy: 0.9661 - 275ms/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "30/30 - 0s - loss: 0.2309 - accuracy: 0.9177 - val_loss: 0.0991 - val_accuracy: 0.9661 - 277ms/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "30/30 - 0s - loss: 0.2291 - accuracy: 0.9208 - val_loss: 0.1036 - val_accuracy: 0.9598 - 275ms/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "30/30 - 0s - loss: 0.2244 - accuracy: 0.9219 - val_loss: 0.0904 - val_accuracy: 0.9672 - 274ms/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "30/30 - 0s - loss: 0.2129 - accuracy: 0.9248 - val_loss: 0.0834 - val_accuracy: 0.9735 - 275ms/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "30/30 - 0s - loss: 0.2146 - accuracy: 0.9248 - val_loss: 0.0839 - val_accuracy: 0.9672 - 275ms/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "30/30 - 0s - loss: 0.2179 - accuracy: 0.9185 - val_loss: 0.0917 - val_accuracy: 0.9661 - 272ms/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "30/30 - 0s - loss: 0.2014 - accuracy: 0.9282 - val_loss: 0.1032 - val_accuracy: 0.9577 - 277ms/epoch - 9ms/step\n",
      "Epoch 43/1000\n",
      "30/30 - 0s - loss: 0.2060 - accuracy: 0.9259 - val_loss: 0.1172 - val_accuracy: 0.9640 - 291ms/epoch - 10ms/step\n",
      "Epoch 44/1000\n",
      "30/30 - 0s - loss: 0.2177 - accuracy: 0.9214 - val_loss: 0.0895 - val_accuracy: 0.9672 - 311ms/epoch - 10ms/step\n",
      "Epoch 45/1000\n",
      "30/30 - 0s - loss: 0.1913 - accuracy: 0.9320 - val_loss: 0.0816 - val_accuracy: 0.9704 - 294ms/epoch - 10ms/step\n",
      "Epoch 46/1000\n",
      "30/30 - 0s - loss: 0.1831 - accuracy: 0.9322 - val_loss: 0.0777 - val_accuracy: 0.9725 - 281ms/epoch - 9ms/step\n",
      "Epoch 47/1000\n",
      "30/30 - 0s - loss: 0.1768 - accuracy: 0.9367 - val_loss: 0.0871 - val_accuracy: 0.9672 - 275ms/epoch - 9ms/step\n",
      "Epoch 48/1000\n",
      "30/30 - 0s - loss: 0.1926 - accuracy: 0.9296 - val_loss: 0.0765 - val_accuracy: 0.9714 - 276ms/epoch - 9ms/step\n",
      "Epoch 49/1000\n",
      "30/30 - 0s - loss: 0.2074 - accuracy: 0.9280 - val_loss: 0.0754 - val_accuracy: 0.9661 - 277ms/epoch - 9ms/step\n",
      "Epoch 50/1000\n",
      "30/30 - 0s - loss: 0.1861 - accuracy: 0.9306 - val_loss: 0.0862 - val_accuracy: 0.9630 - 272ms/epoch - 9ms/step\n",
      "Epoch 51/1000\n",
      "30/30 - 0s - loss: 0.1846 - accuracy: 0.9378 - val_loss: 0.1017 - val_accuracy: 0.9661 - 274ms/epoch - 9ms/step\n",
      "Epoch 52/1000\n",
      "30/30 - 0s - loss: 0.1938 - accuracy: 0.9306 - val_loss: 0.0966 - val_accuracy: 0.9598 - 270ms/epoch - 9ms/step\n",
      "Epoch 53/1000\n",
      "30/30 - 0s - loss: 0.2064 - accuracy: 0.9296 - val_loss: 0.1068 - val_accuracy: 0.9587 - 269ms/epoch - 9ms/step\n",
      "Epoch 54/1000\n",
      "30/30 - 0s - loss: 0.1982 - accuracy: 0.9288 - val_loss: 0.0853 - val_accuracy: 0.9608 - 272ms/epoch - 9ms/step\n",
      "Epoch 55/1000\n",
      "30/30 - 0s - loss: 0.1710 - accuracy: 0.9362 - val_loss: 0.0711 - val_accuracy: 0.9799 - 272ms/epoch - 9ms/step\n",
      "Epoch 56/1000\n",
      "30/30 - 0s - loss: 0.1698 - accuracy: 0.9380 - val_loss: 0.0953 - val_accuracy: 0.9619 - 273ms/epoch - 9ms/step\n",
      "Epoch 57/1000\n",
      "30/30 - 0s - loss: 0.1704 - accuracy: 0.9412 - val_loss: 0.0644 - val_accuracy: 0.9735 - 284ms/epoch - 9ms/step\n",
      "Epoch 58/1000\n",
      "30/30 - 0s - loss: 0.1804 - accuracy: 0.9380 - val_loss: 0.0903 - val_accuracy: 0.9725 - 275ms/epoch - 9ms/step\n",
      "Epoch 59/1000\n",
      "30/30 - 0s - loss: 0.1759 - accuracy: 0.9391 - val_loss: 0.0859 - val_accuracy: 0.9693 - 273ms/epoch - 9ms/step\n",
      "Epoch 60/1000\n",
      "30/30 - 0s - loss: 0.1738 - accuracy: 0.9383 - val_loss: 0.0723 - val_accuracy: 0.9778 - 268ms/epoch - 9ms/step\n",
      "Epoch 61/1000\n",
      "30/30 - 0s - loss: 0.1662 - accuracy: 0.9388 - val_loss: 0.0813 - val_accuracy: 0.9661 - 279ms/epoch - 9ms/step\n",
      "Epoch 62/1000\n",
      "30/30 - 0s - loss: 0.1788 - accuracy: 0.9378 - val_loss: 0.0954 - val_accuracy: 0.9619 - 280ms/epoch - 9ms/step\n",
      "Epoch 63/1000\n",
      "30/30 - 0s - loss: 0.1748 - accuracy: 0.9388 - val_loss: 0.0682 - val_accuracy: 0.9735 - 276ms/epoch - 9ms/step\n",
      "batch_size 128 -> Bu parametrenin test seti üzerindeki başarısı : 97.89%\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugra\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 1s - loss: 2.1251 - accuracy: 0.2182 - val_loss: 1.8202 - val_accuracy: 0.3862 - 746ms/epoch - 50ms/step\n",
      "Epoch 2/1000\n",
      "15/15 - 0s - loss: 1.7564 - accuracy: 0.3257 - val_loss: 1.5242 - val_accuracy: 0.3577 - 179ms/epoch - 12ms/step\n",
      "Epoch 3/1000\n",
      "15/15 - 0s - loss: 1.5437 - accuracy: 0.3773 - val_loss: 1.4263 - val_accuracy: 0.4254 - 202ms/epoch - 13ms/step\n",
      "Epoch 4/1000\n",
      "15/15 - 0s - loss: 1.4516 - accuracy: 0.4403 - val_loss: 1.3338 - val_accuracy: 0.5058 - 180ms/epoch - 12ms/step\n",
      "Epoch 5/1000\n",
      "15/15 - 0s - loss: 1.3581 - accuracy: 0.4890 - val_loss: 1.2176 - val_accuracy: 0.6307 - 180ms/epoch - 12ms/step\n",
      "Epoch 6/1000\n",
      "15/15 - 0s - loss: 1.2455 - accuracy: 0.5592 - val_loss: 1.0648 - val_accuracy: 0.6825 - 175ms/epoch - 12ms/step\n",
      "Epoch 7/1000\n",
      "15/15 - 0s - loss: 1.1018 - accuracy: 0.6018 - val_loss: 0.9086 - val_accuracy: 0.6720 - 167ms/epoch - 11ms/step\n",
      "Epoch 8/1000\n",
      "15/15 - 0s - loss: 0.9894 - accuracy: 0.6362 - val_loss: 0.7808 - val_accuracy: 0.7302 - 161ms/epoch - 11ms/step\n",
      "Epoch 9/1000\n",
      "15/15 - 0s - loss: 0.8917 - accuracy: 0.6627 - val_loss: 0.7248 - val_accuracy: 0.7429 - 163ms/epoch - 11ms/step\n",
      "Epoch 10/1000\n",
      "15/15 - 0s - loss: 0.8061 - accuracy: 0.6992 - val_loss: 0.6560 - val_accuracy: 0.7608 - 170ms/epoch - 11ms/step\n",
      "Epoch 11/1000\n",
      "15/15 - 0s - loss: 0.7581 - accuracy: 0.7138 - val_loss: 0.5833 - val_accuracy: 0.7810 - 164ms/epoch - 11ms/step\n",
      "Epoch 12/1000\n",
      "15/15 - 0s - loss: 0.7240 - accuracy: 0.7178 - val_loss: 0.5511 - val_accuracy: 0.8360 - 140ms/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "15/15 - 0s - loss: 0.6907 - accuracy: 0.7511 - val_loss: 0.5008 - val_accuracy: 0.8392 - 136ms/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "15/15 - 0s - loss: 0.6346 - accuracy: 0.7683 - val_loss: 0.4763 - val_accuracy: 0.8381 - 136ms/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "15/15 - 0s - loss: 0.6014 - accuracy: 0.7826 - val_loss: 0.4385 - val_accuracy: 0.8815 - 138ms/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "15/15 - 0s - loss: 0.5901 - accuracy: 0.7855 - val_loss: 0.4124 - val_accuracy: 0.8921 - 140ms/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "15/15 - 0s - loss: 0.5644 - accuracy: 0.7956 - val_loss: 0.3978 - val_accuracy: 0.8952 - 136ms/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "15/15 - 0s - loss: 0.5491 - accuracy: 0.8046 - val_loss: 0.3734 - val_accuracy: 0.8974 - 144ms/epoch - 10ms/step\n",
      "Epoch 19/1000\n",
      "15/15 - 0s - loss: 0.5235 - accuracy: 0.8115 - val_loss: 0.3491 - val_accuracy: 0.9058 - 153ms/epoch - 10ms/step\n",
      "Epoch 20/1000\n",
      "15/15 - 0s - loss: 0.4957 - accuracy: 0.8237 - val_loss: 0.3363 - val_accuracy: 0.9111 - 140ms/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "15/15 - 0s - loss: 0.4820 - accuracy: 0.8253 - val_loss: 0.3215 - val_accuracy: 0.9153 - 139ms/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "15/15 - 0s - loss: 0.4661 - accuracy: 0.8353 - val_loss: 0.3258 - val_accuracy: 0.9026 - 136ms/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "15/15 - 0s - loss: 0.4543 - accuracy: 0.8313 - val_loss: 0.2985 - val_accuracy: 0.9111 - 139ms/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "15/15 - 0s - loss: 0.4407 - accuracy: 0.8372 - val_loss: 0.2823 - val_accuracy: 0.9175 - 148ms/epoch - 10ms/step\n",
      "Epoch 25/1000\n",
      "15/15 - 0s - loss: 0.4227 - accuracy: 0.8459 - val_loss: 0.2794 - val_accuracy: 0.9206 - 161ms/epoch - 11ms/step\n",
      "Epoch 26/1000\n",
      "15/15 - 0s - loss: 0.4101 - accuracy: 0.8525 - val_loss: 0.2688 - val_accuracy: 0.9196 - 158ms/epoch - 11ms/step\n",
      "Epoch 27/1000\n",
      "15/15 - 0s - loss: 0.4172 - accuracy: 0.8441 - val_loss: 0.2618 - val_accuracy: 0.9291 - 158ms/epoch - 11ms/step\n",
      "Epoch 28/1000\n",
      "15/15 - 0s - loss: 0.4055 - accuracy: 0.8539 - val_loss: 0.2636 - val_accuracy: 0.9238 - 150ms/epoch - 10ms/step\n",
      "Epoch 29/1000\n",
      "15/15 - 0s - loss: 0.3986 - accuracy: 0.8528 - val_loss: 0.2527 - val_accuracy: 0.9312 - 159ms/epoch - 11ms/step\n",
      "Epoch 30/1000\n",
      "15/15 - 0s - loss: 0.3724 - accuracy: 0.8681 - val_loss: 0.2331 - val_accuracy: 0.9386 - 160ms/epoch - 11ms/step\n",
      "Epoch 31/1000\n",
      "15/15 - 0s - loss: 0.3653 - accuracy: 0.8607 - val_loss: 0.2333 - val_accuracy: 0.9291 - 157ms/epoch - 10ms/step\n",
      "Epoch 32/1000\n",
      "15/15 - 0s - loss: 0.3633 - accuracy: 0.8692 - val_loss: 0.2251 - val_accuracy: 0.9280 - 158ms/epoch - 11ms/step\n",
      "Epoch 33/1000\n",
      "15/15 - 0s - loss: 0.3686 - accuracy: 0.8692 - val_loss: 0.2335 - val_accuracy: 0.9312 - 158ms/epoch - 11ms/step\n",
      "Epoch 34/1000\n",
      "15/15 - 0s - loss: 0.3559 - accuracy: 0.8703 - val_loss: 0.2237 - val_accuracy: 0.9450 - 158ms/epoch - 11ms/step\n",
      "Epoch 35/1000\n",
      "15/15 - 0s - loss: 0.3459 - accuracy: 0.8750 - val_loss: 0.2116 - val_accuracy: 0.9439 - 159ms/epoch - 11ms/step\n",
      "Epoch 36/1000\n",
      "15/15 - 0s - loss: 0.3435 - accuracy: 0.8827 - val_loss: 0.1995 - val_accuracy: 0.9503 - 158ms/epoch - 11ms/step\n",
      "Epoch 37/1000\n",
      "15/15 - 0s - loss: 0.3453 - accuracy: 0.8793 - val_loss: 0.1912 - val_accuracy: 0.9492 - 176ms/epoch - 12ms/step\n",
      "Epoch 38/1000\n",
      "15/15 - 0s - loss: 0.3163 - accuracy: 0.8901 - val_loss: 0.1904 - val_accuracy: 0.9471 - 154ms/epoch - 10ms/step\n",
      "Epoch 39/1000\n",
      "15/15 - 0s - loss: 0.3212 - accuracy: 0.8830 - val_loss: 0.1978 - val_accuracy: 0.9439 - 157ms/epoch - 10ms/step\n",
      "Epoch 40/1000\n",
      "15/15 - 0s - loss: 0.3205 - accuracy: 0.8885 - val_loss: 0.1882 - val_accuracy: 0.9503 - 153ms/epoch - 10ms/step\n",
      "Epoch 41/1000\n",
      "15/15 - 0s - loss: 0.2819 - accuracy: 0.9010 - val_loss: 0.1732 - val_accuracy: 0.9545 - 155ms/epoch - 10ms/step\n",
      "Epoch 42/1000\n",
      "15/15 - 0s - loss: 0.3023 - accuracy: 0.8909 - val_loss: 0.1572 - val_accuracy: 0.9513 - 160ms/epoch - 11ms/step\n",
      "Epoch 43/1000\n",
      "15/15 - 0s - loss: 0.3054 - accuracy: 0.8922 - val_loss: 0.1524 - val_accuracy: 0.9503 - 160ms/epoch - 11ms/step\n",
      "Epoch 44/1000\n",
      "15/15 - 0s - loss: 0.2821 - accuracy: 0.9034 - val_loss: 0.1520 - val_accuracy: 0.9534 - 157ms/epoch - 10ms/step\n",
      "Epoch 45/1000\n",
      "15/15 - 0s - loss: 0.2775 - accuracy: 0.9010 - val_loss: 0.1655 - val_accuracy: 0.9471 - 154ms/epoch - 10ms/step\n",
      "Epoch 46/1000\n",
      "15/15 - 0s - loss: 0.2810 - accuracy: 0.8989 - val_loss: 0.1461 - val_accuracy: 0.9577 - 156ms/epoch - 10ms/step\n",
      "Epoch 47/1000\n",
      "15/15 - 0s - loss: 0.2697 - accuracy: 0.9039 - val_loss: 0.1437 - val_accuracy: 0.9534 - 156ms/epoch - 10ms/step\n",
      "Epoch 48/1000\n",
      "15/15 - 0s - loss: 0.2645 - accuracy: 0.9050 - val_loss: 0.1392 - val_accuracy: 0.9534 - 157ms/epoch - 10ms/step\n",
      "Epoch 49/1000\n",
      "15/15 - 0s - loss: 0.2601 - accuracy: 0.9100 - val_loss: 0.1389 - val_accuracy: 0.9556 - 162ms/epoch - 11ms/step\n",
      "Epoch 50/1000\n",
      "15/15 - 0s - loss: 0.2590 - accuracy: 0.9028 - val_loss: 0.1315 - val_accuracy: 0.9587 - 157ms/epoch - 10ms/step\n",
      "Epoch 51/1000\n",
      "15/15 - 0s - loss: 0.2481 - accuracy: 0.9097 - val_loss: 0.1202 - val_accuracy: 0.9598 - 158ms/epoch - 11ms/step\n",
      "Epoch 52/1000\n",
      "15/15 - 0s - loss: 0.2380 - accuracy: 0.9145 - val_loss: 0.1208 - val_accuracy: 0.9566 - 159ms/epoch - 11ms/step\n",
      "Epoch 53/1000\n",
      "15/15 - 0s - loss: 0.2494 - accuracy: 0.9084 - val_loss: 0.1247 - val_accuracy: 0.9577 - 150ms/epoch - 10ms/step\n",
      "Epoch 54/1000\n",
      "15/15 - 0s - loss: 0.2577 - accuracy: 0.9065 - val_loss: 0.1291 - val_accuracy: 0.9577 - 149ms/epoch - 10ms/step\n",
      "Epoch 55/1000\n",
      "15/15 - 0s - loss: 0.2332 - accuracy: 0.9195 - val_loss: 0.1255 - val_accuracy: 0.9556 - 154ms/epoch - 10ms/step\n",
      "Epoch 56/1000\n",
      "15/15 - 0s - loss: 0.2397 - accuracy: 0.9174 - val_loss: 0.1125 - val_accuracy: 0.9587 - 158ms/epoch - 11ms/step\n",
      "Epoch 57/1000\n",
      "15/15 - 0s - loss: 0.2274 - accuracy: 0.9153 - val_loss: 0.1094 - val_accuracy: 0.9619 - 163ms/epoch - 11ms/step\n",
      "Epoch 58/1000\n",
      "15/15 - 0s - loss: 0.2313 - accuracy: 0.9158 - val_loss: 0.1035 - val_accuracy: 0.9683 - 165ms/epoch - 11ms/step\n",
      "Epoch 59/1000\n",
      "15/15 - 0s - loss: 0.2306 - accuracy: 0.9185 - val_loss: 0.1122 - val_accuracy: 0.9608 - 155ms/epoch - 10ms/step\n",
      "Epoch 60/1000\n",
      "15/15 - 0s - loss: 0.2194 - accuracy: 0.9216 - val_loss: 0.1064 - val_accuracy: 0.9619 - 152ms/epoch - 10ms/step\n",
      "Epoch 61/1000\n",
      "15/15 - 0s - loss: 0.2394 - accuracy: 0.9105 - val_loss: 0.1130 - val_accuracy: 0.9608 - 154ms/epoch - 10ms/step\n",
      "Epoch 62/1000\n",
      "15/15 - 0s - loss: 0.2325 - accuracy: 0.9182 - val_loss: 0.1042 - val_accuracy: 0.9651 - 153ms/epoch - 10ms/step\n",
      "Epoch 63/1000\n",
      "15/15 - 0s - loss: 0.2332 - accuracy: 0.9142 - val_loss: 0.1094 - val_accuracy: 0.9619 - 150ms/epoch - 10ms/step\n",
      "Epoch 64/1000\n",
      "15/15 - 0s - loss: 0.2248 - accuracy: 0.9216 - val_loss: 0.0951 - val_accuracy: 0.9714 - 160ms/epoch - 11ms/step\n",
      "Epoch 65/1000\n",
      "15/15 - 0s - loss: 0.2223 - accuracy: 0.9198 - val_loss: 0.0995 - val_accuracy: 0.9714 - 147ms/epoch - 10ms/step\n",
      "Epoch 66/1000\n",
      "15/15 - 0s - loss: 0.2279 - accuracy: 0.9185 - val_loss: 0.1041 - val_accuracy: 0.9672 - 165ms/epoch - 11ms/step\n",
      "Epoch 67/1000\n",
      "15/15 - 0s - loss: 0.2099 - accuracy: 0.9322 - val_loss: 0.0995 - val_accuracy: 0.9608 - 155ms/epoch - 10ms/step\n",
      "Epoch 68/1000\n",
      "15/15 - 0s - loss: 0.2172 - accuracy: 0.9227 - val_loss: 0.1038 - val_accuracy: 0.9619 - 152ms/epoch - 10ms/step\n",
      "Epoch 69/1000\n",
      "15/15 - 0s - loss: 0.2256 - accuracy: 0.9171 - val_loss: 0.1085 - val_accuracy: 0.9630 - 157ms/epoch - 10ms/step\n",
      "Epoch 70/1000\n",
      "15/15 - 0s - loss: 0.2156 - accuracy: 0.9253 - val_loss: 0.1020 - val_accuracy: 0.9651 - 159ms/epoch - 11ms/step\n",
      "batch_size 256 -> Bu parametrenin test seti üzerindeki başarısı : 97.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bugra\\AppData\\Local\\Temp\\ipykernel_2232\\901433257.py:44: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pre = TP / (TP + FP)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  8.        ,   0.99254799,   0.87028436,   0.92878438,\n",
       "          0.99580005,   0.88562872],\n",
       "       [ 16.        ,   0.99345126,   0.93716675,   0.90542786,\n",
       "          0.99643437,   0.91534213],\n",
       "       [ 32.        ,   0.99239744,   0.81483251,          nan,\n",
       "          0.99574461,          nan],\n",
       "       [ 64.        ,   0.98976289,   0.83761611,   0.88078991,\n",
       "          0.99433665,   0.84990181],\n",
       "       [128.        ,   0.99360181,   0.87883621,   0.92001412,\n",
       "          0.99647786,   0.88823013],\n",
       "       [256.        ,   0.99337599,   0.85742331,          nan,\n",
       "          0.99633718,          nan]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batches = [8, 16, 32, 64, 128, 256]\n",
    "for i in batches:\n",
    "    ann_model(X_train, y_train, X_test, y_test, i)\n",
    "\n",
    "acc_scores_ann = np.array(acc_scores_ann)\n",
    "acc_scores_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>acc</th>\n",
       "      <th>sen</th>\n",
       "      <th>pre</th>\n",
       "      <th>spe</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.992548</td>\n",
       "      <td>0.870284</td>\n",
       "      <td>0.928784</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.885629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.993451</td>\n",
       "      <td>0.937167</td>\n",
       "      <td>0.905428</td>\n",
       "      <td>0.996434</td>\n",
       "      <td>0.915342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.989763</td>\n",
       "      <td>0.837616</td>\n",
       "      <td>0.880790</td>\n",
       "      <td>0.994337</td>\n",
       "      <td>0.849902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.993602</td>\n",
       "      <td>0.878836</td>\n",
       "      <td>0.920014</td>\n",
       "      <td>0.996478</td>\n",
       "      <td>0.888230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size       acc       sen       pre       spe        f1\n",
       "0         8.0  0.992548  0.870284  0.928784  0.995800  0.885629\n",
       "1        16.0  0.993451  0.937167  0.905428  0.996434  0.915342\n",
       "3        64.0  0.989763  0.837616  0.880790  0.994337  0.849902\n",
       "4       128.0  0.993602  0.878836  0.920014  0.996478  0.888230"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores_df = pd.DataFrame(acc_scores_ann, columns=['batch_size', 'acc', 'sen', 'pre', 'spe','f1'])\n",
    "acc_scores_df.dropna().to_csv('ann_test_ac_df.csv')\n",
    "acc_scores_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yukarıdaki başarılar göz önünde bulundurulduğunda ann optimum test başarısını %99,36'yla 128 batch_size değerinde vermiştir. </br>\n",
    "Tüm değerler csv dosyası olarak kaydedilmiştir."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7655d9d87d72f7863ec8a6d3178f838b8e50288ba076228c8841638c6799c4ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
